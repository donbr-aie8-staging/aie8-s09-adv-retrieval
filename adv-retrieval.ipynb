{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ü§ù Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/Projects_with_Domains.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Project Title\",\n",
        "      \"Project Domain\",\n",
        "      \"Secondary Domain\",\n",
        "      \"Description\",\n",
        "      \"Judge Comments\",\n",
        "      \"Score\",\n",
        "      \"Project Name\",\n",
        "      \"Judge Score\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "synthetic_usecase_data = loader.load()\n",
        "\n",
        "for doc in synthetic_usecase_data:\n",
        "    doc.page_content = doc.metadata[\"Description\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/Projects_with_Domains.csv', 'row': 0, 'Project Title': 'InsightAI 1', 'Project Domain': 'Security', 'Secondary Domain': 'Finance / FinTech', 'Description': 'A low-latency inference system for multimodal agents in autonomous systems.', 'Judge Comments': 'Technically ambitious and well-executed.', 'Score': '85', 'Project Name': 'Project Aurora', 'Judge Score': '9.5'}, page_content='A low-latency inference system for multimodal agents in autonomous systems.')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_usecase_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    synthetic_usecase_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Synthetic_Usecases\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common project domain in the provided data is \"Healthcare / MedTech,\" which appears three times among the listed projects.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are use cases related to security. Specifically, one project titled \"Pathfinder 24\" focuses on an AI-powered platform optimizing logistics routes for sustainability, which also has a secondary domain of Security. Additionally, there is a project called \"WealthifyAI\" (though its primary focus is on privacy in healthcare applications using federated learning) that could have security implications.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The judges generally had positive comments about the fintech projects. For example, one project was described as having \"impressive real-world impact,\" and another was praised as a \"clever solution with measurable environmental benefit.\" Overall, the comments highlight that the fintech projects were considered innovative, well-executed, and impactful by the judges.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(synthetic_usecase_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the project domains mentioned include Productivity Assistants, E‚Äëcommerce / Marketplaces, Healthcare / MedTech, and Finance / FinTech. Since there are multiple projects in the Finance / FinTech domain (examples include \"PulseAI 50\" and \"DocuCheck 47\"), it appears to be the most common project domain among the examples.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there was a use case related to security. The project titled \"SecureNest 49\" is in the domain of E‚Äëcommerce / Marketplaces and Legal / Compliance, and it involves a document summarization and retrieval system for enterprise knowledge bases, which can relate to security and compliance concerns.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The judges had positive comments about the fintech projects. Specifically, for the project \"SynthMind,\" they noted that it was \"Conceptually strong but results need more benchmarking,\" and gave it a high score of 9.6.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the most common project domain appears to be \"Security,\" as it is listed as the project domain for one of the projects. However, with only three examples, it\\'s not definitive. If these are representative of the larger dataset, \"Security\" seems to be prominent, though more data would be needed for a conclusive answer.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, there are no specific use cases explicitly related to security. The use cases mentioned focus on federated learning to improve privacy in healthcare applications, but there is no direct mention of security-related use cases.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The judges had positive comments about the fintech projects. For example, in the case of the project \"Pathfinder 27\" in the Finance / FinTech domain, the judges highlighted \"excellent code quality and use of open-source libraries.\"'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common project domain in the provided data appears to be \"Healthcare / MedTech,\" which is listed multiple times across different projects.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are use cases related to security. Specifically, one project titled \"Project Aurora\" focuses on a low-latency inference system for multimodal agents in autonomous systems, which is categorized under the Security domain.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Judges had positive remarks about the fintech projects. For example, they described the project \"SkyForge\" as a \"clever solution with measurable environmental benefit,\" and \"LatticeFlow\" was noted for its \"excellent code quality and use of open-source libraries.\" Overall, the judges appreciated the technical maturity, validation, and innovative aspects of these fintech projects.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = synthetic_usecase_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the most common project domain appears to be \"Healthcare / MedTech,\" as it is mentioned multiple times among the examples.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, there do not appear to be any use cases explicitly related to security. The projects mentioned mainly focus on federated learning to improve privacy in healthcare applications, but no specific security use cases are noted.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The judges had positive comments about the projects. For example, they described the project \"LatticeFlow\" as a \"promising idea with robust experimental validation,\" and \"PixelSense\" as having a \"comprehensive and technically mature approach.\" Additionally, \"SynthMind\" was recognized for being \"solid work with impressive real-world impact,\" and \"GreenPulse\" was noted as \"technically ambitious and well-executed.\" Overall, the judges praised the projects for their potential, technical quality, and real-world relevance.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the most common project domain appears to be \"Legal / Compliance,\" as it is listed multiple times among the sample projects.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are use cases related to security. One example is \"Project Aurora,\" which involves a low-latency inference system for multimodal agents in autonomous systems.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Judges generally had positive comments about the fintech projects. For example, they described the Pathfinder project as having \"Excellent code quality and use of open-source libraries,\" and the DocuCheck project as being a \"Conceptually strong but results need more benchmarking.\" The scores also reflect favorable evaluations, with scores like 81 and 87 and judge scores of 9.8 and 9.6, indicating high regard for these projects.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(synthetic_usecase_data[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Synthetic_Usecase_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common project domain in the provided data is \"Legal / Compliance,\" which appears twice. Other domains like \"Customer Support / Helpdesk,\" \"Developer Tools / DevEx,\" \"Writing & Content,\" and \"Finance / FinTech\" also appear multiple times, but not more frequently than \"Legal / Compliance\" in this dataset.'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common project domain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are usecases related to security. Specifically, there are projects such as \"SynthMind,\" which involves a medical imaging solution, and \"BioForge,\" which is a medical imaging solution with a focus on enhancing early diagnosis through vision transformers. Additionally, the project \"Neural Canvas\" addresses a low-latency inference system for multimodal agents in autonomous systems, which can be relevant to security applications.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Were there any usecases about security?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Judges had positive comments about the fintech projects. For example, they described the project \"WealthifyAI 16\" as having a \"comprehensive and technically mature approach,\" and \"AutoMate 5\" as a \"forward-looking idea with solid supporting data.\" Overall, the judges appreciated the technical ambition, execution quality, and potential impact of these projects.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What did judges have to say about the fintech projects?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ü§ù Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### üèóÔ∏è Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "## take synthetic_usecase_data and load into a HF dataset\n",
        "\n",
        "## use ragas to generate a golden testset\n",
        "\n",
        "## load the golden testset into a HF dataset\n",
        "\n",
        "## load the golden testset into LangSmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# synthetic_usecase_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/Projects_with_Domains.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Project Title\",\n",
        "      \"Project Domain\",\n",
        "      \"Secondary Domain\",\n",
        "      \"Description\",\n",
        "      \"Judge Comments\",\n",
        "      \"Score\",\n",
        "      \"Project Name\",\n",
        "      \"Judge Score\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "ragas_usecase_data = loader.load()\n",
        "\n",
        "for doc in ragas_usecase_data:\n",
        "    title = doc.metadata.get(\"Project Title\", \"\")\n",
        "    domain = doc.metadata.get(\"Project Domain\", \"\")\n",
        "    secondary = doc.metadata.get(\"Secondary Domain\", \"\")\n",
        "    desc = doc.metadata.get(\"Description\", \"\")\n",
        "    \n",
        "    doc.page_content = f\"{title}\\nDomain: {domain}\\nSecondary Domain: {secondary}\\nDescription: {desc}\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "ragas_loader = CSVLoader(\n",
        "    file_path=f\"./data/Projects_with_Domains.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Judge Comments\",\n",
        "      \"Score\",\n",
        "      \"Project Name\",\n",
        "      \"Judge Score\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "ragas_usecase_data2 = ragas_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/Projects_with_Domains.csv', 'row': 0, 'Judge Comments': 'Technically ambitious and well-executed.', 'Score': '85', 'Project Name': 'Project Aurora', 'Judge Score': '9.5'}, page_content='Project Title: InsightAI 1\\nProject Domain: Security\\nSecondary Domain: Finance / FinTech\\nDescription: A low-latency inference system for multimodal agents in autonomous systems.')"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ragas_usecase_data2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ragas_usecase_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ragas_usecase_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_73705/3890116666.py:7: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use the modern LLM providers instead: from ragas.llms.base import llm_factory; llm = llm_factory('gpt-4o-mini') or from ragas.llms.base import instructor_llm_factory; llm = instructor_llm_factory('openai', client=openai_client)\n",
            "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n"
          ]
        }
      ],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import OpenAIEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "import openai\n",
        "\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
        "openai_client = openai.OpenAI()\n",
        "generator_embeddings = OpenAIEmbeddings(client=openai_client, model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 50, relationships: 0)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import KnowledgeGraph\n",
        "from ragas.testset.graph import Node, NodeType\n",
        "\n",
        "\n",
        "kg = KnowledgeGraph()\n",
        "\n",
        "for doc in ragas_usecase_data:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
        "        )\n",
        "    )\n",
        "\n",
        "kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f897934a85d4fabb9fd79177541267d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'headlines' already exists in node 'ec091a'. Skipping!\n",
            "Property 'headlines' already exists in node '56e3e6'. Skipping!\n",
            "Property 'headlines' already exists in node 'b4aba8'. Skipping!\n",
            "Property 'headlines' already exists in node 'b32f69'. Skipping!\n",
            "Property 'headlines' already exists in node '260f81'. Skipping!\n",
            "Property 'headlines' already exists in node '565241'. Skipping!\n",
            "Property 'headlines' already exists in node 'c68718'. Skipping!\n",
            "Property 'headlines' already exists in node 'f7c747'. Skipping!\n",
            "Property 'headlines' already exists in node '78cb51'. Skipping!\n",
            "Property 'headlines' already exists in node '63f015'. Skipping!\n",
            "Property 'headlines' already exists in node '2413dd'. Skipping!\n",
            "Property 'headlines' already exists in node 'c62ab3'. Skipping!\n",
            "Property 'headlines' already exists in node 'f95401'. Skipping!\n",
            "Property 'headlines' already exists in node '1ec025'. Skipping!\n",
            "Property 'headlines' already exists in node 'c68a19'. Skipping!\n",
            "Property 'headlines' already exists in node '61578b'. Skipping!\n",
            "Property 'headlines' already exists in node '609b9f'. Skipping!\n",
            "Property 'headlines' already exists in node 'b5409d'. Skipping!\n",
            "Property 'headlines' already exists in node '9ccea1'. Skipping!\n",
            "Property 'headlines' already exists in node '1f8ebb'. Skipping!\n",
            "Property 'headlines' already exists in node '8508d4'. Skipping!\n",
            "Property 'headlines' already exists in node '5ac616'. Skipping!\n",
            "Property 'headlines' already exists in node '0852af'. Skipping!\n",
            "Property 'headlines' already exists in node '404086'. Skipping!\n",
            "Property 'headlines' already exists in node 'f5382b'. Skipping!\n",
            "Property 'headlines' already exists in node '664c91'. Skipping!\n",
            "Property 'headlines' already exists in node 'ea0f22'. Skipping!\n",
            "Property 'headlines' already exists in node '2e36a9'. Skipping!\n",
            "Property 'headlines' already exists in node 'fa44cd'. Skipping!\n",
            "Property 'headlines' already exists in node 'd2a879'. Skipping!\n",
            "Property 'headlines' already exists in node 'f64a10'. Skipping!\n",
            "Property 'headlines' already exists in node 'a1d3dc'. Skipping!\n",
            "Property 'headlines' already exists in node 'c7bc4d'. Skipping!\n",
            "Property 'headlines' already exists in node 'f7c681'. Skipping!\n",
            "Property 'headlines' already exists in node '59eb20'. Skipping!\n",
            "Property 'headlines' already exists in node 'b01236'. Skipping!\n",
            "Property 'headlines' already exists in node 'b088d5'. Skipping!\n",
            "Property 'headlines' already exists in node '155336'. Skipping!\n",
            "Property 'headlines' already exists in node '910758'. Skipping!\n",
            "Property 'headlines' already exists in node '609b9f'. Skipping!\n",
            "Property 'headlines' already exists in node 'f7c747'. Skipping!\n",
            "Property 'headlines' already exists in node '1e007c'. Skipping!\n",
            "Property 'headlines' already exists in node 'c68718'. Skipping!\n",
            "Property 'headlines' already exists in node '0dea9f'. Skipping!\n",
            "Property 'headlines' already exists in node 'c65ee1'. Skipping!\n",
            "Property 'headlines' already exists in node '60a280'. Skipping!\n",
            "Property 'headlines' already exists in node '78bb0d'. Skipping!\n",
            "Property 'headlines' already exists in node '2e6ce0'. Skipping!\n",
            "Property 'headlines' already exists in node '6485f7'. Skipping!\n",
            "Property 'headlines' already exists in node 'c0d881'. Skipping!\n",
            "Property 'headlines' already exists in node '608181'. Skipping!\n",
            "Property 'headlines' already exists in node '8c5671'. Skipping!\n",
            "Property 'headlines' already exists in node 'f95401'. Skipping!\n",
            "Property 'headlines' already exists in node '294403'. Skipping!\n",
            "Property 'headlines' already exists in node '260f81'. Skipping!\n",
            "Property 'headlines' already exists in node 'b32f69'. Skipping!\n",
            "Property 'headlines' already exists in node '8508d4'. Skipping!\n",
            "Property 'headlines' already exists in node '9ccea1'. Skipping!\n",
            "Property 'headlines' already exists in node '1f8ebb'. Skipping!\n",
            "Property 'headlines' already exists in node '56e3e6'. Skipping!\n",
            "Property 'headlines' already exists in node '63f015'. Skipping!\n",
            "Property 'headlines' already exists in node 'ec091a'. Skipping!\n",
            "Property 'headlines' already exists in node '78cb51'. Skipping!\n",
            "Property 'headlines' already exists in node '2e36a9'. Skipping!\n",
            "Property 'headlines' already exists in node '1ec025'. Skipping!\n",
            "Property 'headlines' already exists in node '565241'. Skipping!\n",
            "Property 'headlines' already exists in node 'b4aba8'. Skipping!\n",
            "Property 'headlines' already exists in node '2413dd'. Skipping!\n",
            "Property 'headlines' already exists in node 'c62ab3'. Skipping!\n",
            "Property 'headlines' already exists in node 'ea0f22'. Skipping!\n",
            "Property 'headlines' already exists in node 'c68a19'. Skipping!\n",
            "Property 'headlines' already exists in node '61578b'. Skipping!\n",
            "Property 'headlines' already exists in node 'f64a10'. Skipping!\n",
            "Property 'headlines' already exists in node '78bb0d'. Skipping!\n",
            "Property 'headlines' already exists in node 'd2a879'. Skipping!\n",
            "Property 'headlines' already exists in node 'f7c681'. Skipping!\n",
            "Property 'headlines' already exists in node '5ac616'. Skipping!\n",
            "Property 'headlines' already exists in node 'b5409d'. Skipping!\n",
            "Property 'headlines' already exists in node '910758'. Skipping!\n",
            "Property 'headlines' already exists in node '664c91'. Skipping!\n",
            "Property 'headlines' already exists in node '59eb20'. Skipping!\n",
            "Property 'headlines' already exists in node 'f5382b'. Skipping!\n",
            "Property 'headlines' already exists in node '0852af'. Skipping!\n",
            "Property 'headlines' already exists in node '404086'. Skipping!\n",
            "Property 'headlines' already exists in node 'b01236'. Skipping!\n",
            "Property 'headlines' already exists in node 'c7bc4d'. Skipping!\n",
            "Property 'headlines' already exists in node 'a1d3dc'. Skipping!\n",
            "Property 'headlines' already exists in node '2e6ce0'. Skipping!\n",
            "Property 'headlines' already exists in node 'fa44cd'. Skipping!\n",
            "Property 'headlines' already exists in node '1e007c'. Skipping!\n",
            "Property 'headlines' already exists in node '155336'. Skipping!\n",
            "Property 'headlines' already exists in node '294403'. Skipping!\n",
            "Property 'headlines' already exists in node '608181'. Skipping!\n",
            "Property 'headlines' already exists in node 'b088d5'. Skipping!\n",
            "Property 'headlines' already exists in node '8c5671'. Skipping!\n",
            "Property 'headlines' already exists in node '60a280'. Skipping!\n",
            "Property 'headlines' already exists in node 'c65ee1'. Skipping!\n",
            "Property 'headlines' already exists in node '0dea9f'. Skipping!\n",
            "Property 'headlines' already exists in node 'c0d881'. Skipping!\n",
            "Property 'headlines' already exists in node '6485f7'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cddf7b12a66647bca9bf10c13f13ca0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7911f197f7074cbfa44351d61c8f0bcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying KeyphrasesExtractor:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'keyphrases' already exists in node '565241'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c747'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b4aba8'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c62ab3'. Skipping!\n",
            "Property 'keyphrases' already exists in node '260f81'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b32f69'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1ec025'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2413dd'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ec091a'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68718'. Skipping!\n",
            "Property 'keyphrases' already exists in node '609b9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node '56e3e6'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f95401'. Skipping!\n",
            "Property 'keyphrases' already exists in node '63f015'. Skipping!\n",
            "Property 'keyphrases' already exists in node '61578b'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68a19'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78cb51'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd2a879'. Skipping!\n",
            "Property 'keyphrases' already exists in node '664c91'. Skipping!\n",
            "Property 'keyphrases' already exists in node '5ac616'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0852af'. Skipping!\n",
            "Property 'keyphrases' already exists in node '59eb20'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b5409d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f64a10'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8508d4'. Skipping!\n",
            "Property 'keyphrases' already exists in node '9ccea1'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1f8ebb'. Skipping!\n",
            "Property 'keyphrases' already exists in node '404086'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b01236'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f5382b'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ea0f22'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c681'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e36a9'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'a1d3dc'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c7bc4d'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e6ce0'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'fa44cd'. Skipping!\n",
            "Property 'keyphrases' already exists in node '910758'. Skipping!\n",
            "Property 'keyphrases' already exists in node '155336'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78bb0d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c747'. Skipping!\n",
            "Property 'keyphrases' already exists in node '609b9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68718'. Skipping!\n",
            "Property 'keyphrases' already exists in node '260f81'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b32f69'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8c5671'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78cb51'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b088d5'. Skipping!\n",
            "Property 'keyphrases' already exists in node '60a280'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c0d881'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c65ee1'. Skipping!\n",
            "Property 'keyphrases' already exists in node '608181'. Skipping!\n",
            "Property 'keyphrases' already exists in node '56e3e6'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1e007c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '294403'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b4aba8'. Skipping!\n",
            "Property 'keyphrases' already exists in node '6485f7'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0dea9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f95401'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ec091a'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2413dd'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8508d4'. Skipping!\n",
            "Property 'keyphrases' already exists in node '61578b'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'a1d3dc'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c681'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b01236'. Skipping!\n",
            "Property 'keyphrases' already exists in node '565241'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68a19'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1ec025'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f64a10'. Skipping!\n",
            "Property 'keyphrases' already exists in node '63f015'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ea0f22'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c62ab3'. Skipping!\n",
            "Property 'keyphrases' already exists in node '59eb20'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e36a9'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1f8ebb'. Skipping!\n",
            "Property 'keyphrases' already exists in node '9ccea1'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c7bc4d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b5409d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f5382b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '155336'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8c5671'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78bb0d'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e6ce0'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0852af'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b088d5'. Skipping!\n",
            "Property 'keyphrases' already exists in node '294403'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd2a879'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'fa44cd'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1e007c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '910758'. Skipping!\n",
            "Property 'keyphrases' already exists in node '60a280'. Skipping!\n",
            "Property 'keyphrases' already exists in node '5ac616'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c0d881'. Skipping!\n",
            "Property 'keyphrases' already exists in node '404086'. Skipping!\n",
            "Property 'keyphrases' already exists in node '664c91'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78cb51'. Skipping!\n",
            "Property 'keyphrases' already exists in node '63f015'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b4aba8'. Skipping!\n",
            "Property 'keyphrases' already exists in node '56e3e6'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ec091a'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c65ee1'. Skipping!\n",
            "Property 'keyphrases' already exists in node '6485f7'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68718'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b32f69'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2413dd'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f95401'. Skipping!\n",
            "Property 'keyphrases' already exists in node '61578b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '608181'. Skipping!\n",
            "Property 'keyphrases' already exists in node '260f81'. Skipping!\n",
            "Property 'keyphrases' already exists in node '609b9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0dea9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c62ab3'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c747'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1ec025'. Skipping!\n",
            "Property 'keyphrases' already exists in node '565241'. Skipping!\n",
            "Property 'keyphrases' already exists in node '9ccea1'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ea0f22'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68a19'. Skipping!\n",
            "Property 'keyphrases' already exists in node '664c91'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0852af'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c681'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd2a879'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1f8ebb'. Skipping!\n",
            "Property 'keyphrases' already exists in node '5ac616'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b01236'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f64a10'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c7bc4d'. Skipping!\n",
            "Property 'keyphrases' already exists in node '404086'. Skipping!\n",
            "Property 'keyphrases' already exists in node '59eb20'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e36a9'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b5409d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'a1d3dc'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'fa44cd'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e6ce0'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8508d4'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f5382b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0dea9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c65ee1'. Skipping!\n",
            "Property 'keyphrases' already exists in node '6485f7'. Skipping!\n",
            "Property 'keyphrases' already exists in node '608181'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68718'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c747'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f95401'. Skipping!\n",
            "Property 'keyphrases' already exists in node '609b9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8c5671'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b32f69'. Skipping!\n",
            "Property 'keyphrases' already exists in node '294403'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c0d881'. Skipping!\n",
            "Property 'keyphrases' already exists in node '155336'. Skipping!\n",
            "Property 'keyphrases' already exists in node '910758'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1e007c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78bb0d'. Skipping!\n",
            "Property 'keyphrases' already exists in node '260f81'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78cb51'. Skipping!\n",
            "Property 'keyphrases' already exists in node '60a280'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b088d5'. Skipping!\n",
            "Property 'keyphrases' already exists in node '56e3e6'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2413dd'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b4aba8'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ec091a'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b01236'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f7c681'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'a1d3dc'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f64a10'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ea0f22'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8508d4'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c68a19'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e36a9'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c62ab3'. Skipping!\n",
            "Property 'keyphrases' already exists in node '565241'. Skipping!\n",
            "Property 'keyphrases' already exists in node '9ccea1'. Skipping!\n",
            "Property 'keyphrases' already exists in node '59eb20'. Skipping!\n",
            "Property 'keyphrases' already exists in node '61578b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1f8ebb'. Skipping!\n",
            "Property 'keyphrases' already exists in node '63f015'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1ec025'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c7bc4d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b5409d'. Skipping!\n",
            "Property 'keyphrases' already exists in node '294403'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c0d881'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b088d5'. Skipping!\n",
            "Property 'keyphrases' already exists in node '404086'. Skipping!\n",
            "Property 'keyphrases' already exists in node '5ac616'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'fa44cd'. Skipping!\n",
            "Property 'keyphrases' already exists in node '664c91'. Skipping!\n",
            "Property 'keyphrases' already exists in node '2e6ce0'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8c5671'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd2a879'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f5382b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '1e007c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '155336'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78bb0d'. Skipping!\n",
            "Property 'keyphrases' already exists in node '60a280'. Skipping!\n",
            "Property 'keyphrases' already exists in node '910758'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0852af'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0dea9f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'c65ee1'. Skipping!\n",
            "Property 'keyphrases' already exists in node '6485f7'. Skipping!\n",
            "Property 'keyphrases' already exists in node '608181'. Skipping!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 200, relationships: 0)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.transforms import apply_transforms\n",
        "from ragas.testset.transforms import HeadlinesExtractor, HeadlineSplitter, KeyphrasesExtractor\n",
        "\n",
        "headline_extractor = HeadlinesExtractor(llm=generator_llm)\n",
        "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
        "keyphrase_extractor = KeyphrasesExtractor(llm=generator_llm)\n",
        "\n",
        "transforms = [\n",
        "    headline_extractor,\n",
        "    headline_splitter,\n",
        "    keyphrase_extractor\n",
        "]\n",
        "\n",
        "apply_transforms(kg, transforms=transforms)\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Persona               | Use Case Type                             | Derived From                                                                |\n",
        "| --------------------- | ----------------------------------------- | --------------------------------------------------------------------------- |\n",
        "| Decision Analyst      | **Asking / Seeking Information**          | ‚ÄúDecision support and information interpretation dominate work-related use‚Äù |\n",
        "| Domain Researcher     | **Knowledge Graph & Multi-hop Retrieval** | Multi-domain structure in `Projects_with_Domains.csv`                       |\n",
        "| Instructional Creator | **Practical Guidance / Tutoring**         | Education & self-learning patterns (10% of usage)                           |\n",
        "| AI Practitioner       | **Evaluation & Coding Assistance**        | Work-related ‚ÄúDoing‚Äù messages (40% overall)                                 |\n",
        "| Creative Strategist   | **Self-Expression / Ideation**            | Growth of ‚ÄúExpressing‚Äù and ‚ÄúCreative Guidance‚Äù segments                     |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.persona import Persona\n",
        "\n",
        "persona_decision_analyst = Persona(\n",
        "    name=\"Decision Analyst\",\n",
        "    role_description=(\n",
        "        \"Uses AI for analytical reasoning and decision support. \"\n",
        "        \"Seeks data-driven insights, summaries, and structured outputs to inform business or policy decisions. \"\n",
        "        \"Values concise factual responses, traceable evidence, and cost-effective solutions.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_domain_researcher = Persona(\n",
        "    name=\"Domain Researcher\",\n",
        "    role_description=(\n",
        "        \"Explores multi-domain knowledge sources (e.g., education, health, finance, engineering). \"\n",
        "        \"Prefers context-rich retrieval with citations and nuanced synthesis. \"\n",
        "        \"Often asks cross-domain 'why/how' questions requiring reasoning beyond surface-level facts.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_instructional_creator = Persona(\n",
        "    name=\"Instructional Creator\",\n",
        "    role_description=(\n",
        "        \"Designs educational or training materials using AI. \"\n",
        "        \"Relies on clear, pedagogical explanations and consistent tone. \"\n",
        "        \"Frequently asks for examples, analogies, or simplified explanations for learners.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_ai_practitioner = Persona(\n",
        "    name=\"AI Practitioner\",\n",
        "    role_description=(\n",
        "        \"Implements and evaluates retrieval-augmented systems. \"\n",
        "        \"Needs structured, reproducible outputs like JSON schemas, test cases, and evaluation metrics. \"\n",
        "        \"Focuses on precision, recall, and factual grounding when comparing retrievers or datasets.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_creative_strategist = Persona(\n",
        "    name=\"Creative Strategist\",\n",
        "    role_description=(\n",
        "        \"Uses AI for ideation, storytelling, and persuasive communication. \"\n",
        "        \"Seeks novel phrasing, emotional resonance, and creative reframing of ideas. \"\n",
        "        \"Frequently explores role-play or scenario-based reasoning.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "personas = [\n",
        "    persona_decision_analyst,\n",
        "    persona_domain_researcher,\n",
        "    persona_instructional_creator,\n",
        "    persona_ai_practitioner,\n",
        "    persona_creative_strategist,\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers.single_hop.specific import (\n",
        "    SingleHopSpecificQuerySynthesizer,\n",
        ")\n",
        "\n",
        "query_distibution = [\n",
        "    (\n",
        "        SingleHopSpecificQuerySynthesizer(llm=generator_llm, property_name=\"headlines\"),\n",
        "        0.5,\n",
        "    ),\n",
        "    (\n",
        "        SingleHopSpecificQuerySynthesizer(\n",
        "            llm=generator_llm, property_name=\"keyphrases\"\n",
        "        ),\n",
        "        0.5,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 200, relationships: 0)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"usecase_data_kg.json\")\n",
        "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
        "usecase_data_kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(\n",
        "    llm=generator_llm,\n",
        "    embedding_model=generator_embeddings,\n",
        "    knowledge_graph=usecase_data_kg,\n",
        "    persona_list=personas,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "481d39b74cb9458d97569f31b89e169e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4857f7f598054a1286ac769406c142f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "user_input",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "reference_contexts",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "reference",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "synthesizer_name",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "c09a7600-ebe9-4099-96ee-60a93a0d8a89",
              "rows": [
                [
                  "0",
                  "Could you explain what AutoMate 11 is and how it is applied in the context of e-commerce and data center energy efficiency?",
                  "['AutoMate 11\\nDomain: E‚Äëcommerce / Marketplaces\\nSecondary Domain: QA / Testing / Validation\\nDescription: A reinforcement learning setup for optimizing energy efficiency in data centers.']",
                  "AutoMate 11 is a reinforcement learning setup designed to optimize energy efficiency in data centers. It is primarily applied within the e-commerce and marketplaces domain, with a secondary focus on quality assurance, testing, and validation.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "1",
                  "why Pathfinder 24 use Secondary Domain Security when it main focus healthcare and MedTech and how it help in logistics routes optimization for sustainability?",
                  "['Pathfinder 24\\nDomain: Healthcare / MedTech\\nSecondary Domain: Security\\nDescription: An AI-powered platform optimizing logistics routes for sustainability.']",
                  "Pathfinder 24 is an AI-powered platform primarily focused on healthcare and MedTech, with a secondary domain in security. This secondary domain likely supports the platform's optimization of logistics routes for sustainability by ensuring secure handling of data and operations within its AI-driven processes.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "2",
                  "What is AutoMate 11 used for in e-commerce?",
                  "['AutoMate 11\\nDomain: E‚Äëcommerce / Marketplaces\\nSecondary Domain: QA / Testing / Validation\\nDescription: A reinforcement learning setup for optimizing energy efficiency in data centers.']",
                  "AutoMate 11 is a reinforcement learning setup designed to optimize energy efficiency in data centers within the e-commerce and marketplaces domain.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "3",
                  "Can you explane how the Descripton: An AI-powered platform optimizing logistics routes for sustainibility works in the context of healthcare and security domains?",
                  "['Pathfinder 24\\nDomain: Healthcare / MedTech\\nSecondary Domain: Security\\nDescription: An AI-powered platform optimizing logistics routes for sustainability.']",
                  "Pathfinder 24 is an AI-powered platform that optimizes logistics routes for sustainability. It operates primarily within the healthcare and MedTech domain, with a secondary focus on security.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "4",
                  "Can you explane what AutoMate 11 is and how it helps with energy efficency in data centers?",
                  "['AutoMate 11\\nDomain: E‚Äëcommerce / Marketplaces\\nSecondary Domain: QA / Testing / Validation\\nDescription: A reinforcement learning setup for optimizing energy efficiency in data centers.']",
                  "AutoMate 11 is a reinforcement learning setup designed to optimize energy efficiency in data centers.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "5",
                  "What is InsightAI 1 and how does it relate to security in autonomous systems?",
                  "['InsightAI 1\\nDomain: Security\\nSecondary Domain: Finance / FinTech\\nDescription: A low-latency inference system for multimodal agents in autonomous systems.']",
                  "InsightAI 1 is a low-latency inference system designed for multimodal agents in autonomous systems, operating within the domain of security and with a secondary focus on finance and FinTech.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "6",
                  "what is Productivity Assistants in ShopSmart 2?",
                  "['ShopSmart 2\\nDomain: Developer Tools / DevEx\\nSecondary Domain: Productivity Assistants\\nDescription: A simulation environment for embodied AI agents using Unreal integration.']",
                  "In ShopSmart 2, Productivity Assistants is the secondary domain related to a simulation environment for embodied AI agents using Unreal integration.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "7",
                  "How does WealthifyAI 3 contribute to enhancing DevEx within the developer tools domain?",
                  "['WealthifyAI 3\\nDomain: Developer Tools / DevEx\\nSecondary Domain: Security\\nDescription: A medical imaging solution improving early diagnosis through vision transformers.']",
                  "WealthifyAI 3 operates in the developer tools and DevEx domain by providing a medical imaging solution that improves early diagnosis through the use of vision transformers.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "8",
                  "Could you explain how the term Finance is related to the MediMind 4 generative model within the context of e-commerce and marketplaces?",
                  "['MediMind 4\\nDomain: E‚Äëcommerce / Marketplaces\\nSecondary Domain: Finance / FinTech\\nDescription: A generative model enabling adaptive speech synthesis for accessibility.']",
                  "MediMind 4 operates primarily in the e-commerce and marketplaces domain, with Finance and FinTech as its secondary domain. This indicates that the generative model incorporates financial technology aspects, likely to support adaptive speech synthesis applications that enhance accessibility within financial transactions or services in these marketplaces.",
                  "single_hop_specific_query_synthesizer"
                ],
                [
                  "9",
                  "Could you explain how the term Finance relates to the AutoMate 5 bioinformatics pipeline described in the context?",
                  "['AutoMate 5\\nDomain: Finance / FinTech\\nSecondary Domain: Healthcare / MedTech\\nDescription: A bioinformatics pipeline leveraging transformers for genome annotation.']",
                  "AutoMate 5 is primarily associated with the Finance domain, specifically Finance and FinTech, while also having a secondary connection to Healthcare and MedTech. Despite being a bioinformatics pipeline leveraging transformers for genome annotation, its main domain classification is Finance.",
                  "single_hop_specific_query_synthesizer"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 10
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Could you explain what AutoMate 11 is and how ...</td>\n",
              "      <td>[AutoMate 11\\nDomain: E‚Äëcommerce / Marketplace...</td>\n",
              "      <td>AutoMate 11 is a reinforcement learning setup ...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>why Pathfinder 24 use Secondary Domain Securit...</td>\n",
              "      <td>[Pathfinder 24\\nDomain: Healthcare / MedTech\\n...</td>\n",
              "      <td>Pathfinder 24 is an AI-powered platform primar...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is AutoMate 11 used for in e-commerce?</td>\n",
              "      <td>[AutoMate 11\\nDomain: E‚Äëcommerce / Marketplace...</td>\n",
              "      <td>AutoMate 11 is a reinforcement learning setup ...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can you explane how the Descripton: An AI-powe...</td>\n",
              "      <td>[Pathfinder 24\\nDomain: Healthcare / MedTech\\n...</td>\n",
              "      <td>Pathfinder 24 is an AI-powered platform that o...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can you explane what AutoMate 11 is and how it...</td>\n",
              "      <td>[AutoMate 11\\nDomain: E‚Äëcommerce / Marketplace...</td>\n",
              "      <td>AutoMate 11 is a reinforcement learning setup ...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is InsightAI 1 and how does it relate to ...</td>\n",
              "      <td>[InsightAI 1\\nDomain: Security\\nSecondary Doma...</td>\n",
              "      <td>InsightAI 1 is a low-latency inference system ...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>what is Productivity Assistants in ShopSmart 2?</td>\n",
              "      <td>[ShopSmart 2\\nDomain: Developer Tools / DevEx\\...</td>\n",
              "      <td>In ShopSmart 2, Productivity Assistants is the...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does WealthifyAI 3 contribute to enhancing...</td>\n",
              "      <td>[WealthifyAI 3\\nDomain: Developer Tools / DevE...</td>\n",
              "      <td>WealthifyAI 3 operates in the developer tools ...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Could you explain how the term Finance is rela...</td>\n",
              "      <td>[MediMind 4\\nDomain: E‚Äëcommerce / Marketplaces...</td>\n",
              "      <td>MediMind 4 operates primarily in the e-commerc...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Could you explain how the term Finance relates...</td>\n",
              "      <td>[AutoMate 5\\nDomain: Finance / FinTech\\nSecond...</td>\n",
              "      <td>AutoMate 5 is primarily associated with the Fi...</td>\n",
              "      <td>single_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  Could you explain what AutoMate 11 is and how ...   \n",
              "1  why Pathfinder 24 use Secondary Domain Securit...   \n",
              "2        What is AutoMate 11 used for in e-commerce?   \n",
              "3  Can you explane how the Descripton: An AI-powe...   \n",
              "4  Can you explane what AutoMate 11 is and how it...   \n",
              "5  What is InsightAI 1 and how does it relate to ...   \n",
              "6    what is Productivity Assistants in ShopSmart 2?   \n",
              "7  How does WealthifyAI 3 contribute to enhancing...   \n",
              "8  Could you explain how the term Finance is rela...   \n",
              "9  Could you explain how the term Finance relates...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [AutoMate 11\\nDomain: E‚Äëcommerce / Marketplace...   \n",
              "1  [Pathfinder 24\\nDomain: Healthcare / MedTech\\n...   \n",
              "2  [AutoMate 11\\nDomain: E‚Äëcommerce / Marketplace...   \n",
              "3  [Pathfinder 24\\nDomain: Healthcare / MedTech\\n...   \n",
              "4  [AutoMate 11\\nDomain: E‚Äëcommerce / Marketplace...   \n",
              "5  [InsightAI 1\\nDomain: Security\\nSecondary Doma...   \n",
              "6  [ShopSmart 2\\nDomain: Developer Tools / DevEx\\...   \n",
              "7  [WealthifyAI 3\\nDomain: Developer Tools / DevE...   \n",
              "8  [MediMind 4\\nDomain: E‚Äëcommerce / Marketplaces...   \n",
              "9  [AutoMate 5\\nDomain: Finance / FinTech\\nSecond...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  AutoMate 11 is a reinforcement learning setup ...   \n",
              "1  Pathfinder 24 is an AI-powered platform primar...   \n",
              "2  AutoMate 11 is a reinforcement learning setup ...   \n",
              "3  Pathfinder 24 is an AI-powered platform that o...   \n",
              "4  AutoMate 11 is a reinforcement learning setup ...   \n",
              "5  InsightAI 1 is a low-latency inference system ...   \n",
              "6  In ShopSmart 2, Productivity Assistants is the...   \n",
              "7  WealthifyAI 3 operates in the developer tools ...   \n",
              "8  MediMind 4 operates primarily in the e-commerc...   \n",
              "9  AutoMate 5 is primarily associated with the Fi...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0  single_hop_specific_query_synthesizer  \n",
              "1  single_hop_specific_query_synthesizer  \n",
              "2  single_hop_specific_query_synthesizer  \n",
              "3  single_hop_specific_query_synthesizer  \n",
              "4  single_hop_specific_query_synthesizer  \n",
              "5  single_hop_specific_query_synthesizer  \n",
              "6  single_hop_specific_query_synthesizer  \n",
              "7  single_hop_specific_query_synthesizer  \n",
              "8  single_hop_specific_query_synthesizer  \n",
              "9  single_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset = generator.generate(testset_size=10, query_distribution=query_distibution)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "153\n",
            "172\n",
            "167\n",
            "166\n",
            "161\n",
            "162\n",
            "166\n",
            "165\n",
            "164\n",
            "176\n",
            "183\n",
            "155\n",
            "162\n",
            "149\n",
            "161\n",
            "172\n",
            "160\n",
            "173\n",
            "162\n",
            "166\n",
            "168\n",
            "165\n",
            "168\n",
            "153\n",
            "167\n",
            "168\n",
            "167\n",
            "142\n",
            "151\n",
            "175\n",
            "184\n",
            "168\n",
            "179\n",
            "169\n",
            "162\n",
            "148\n",
            "161\n",
            "177\n",
            "163\n",
            "161\n",
            "181\n",
            "170\n",
            "182\n",
            "157\n",
            "175\n",
            "167\n",
            "158\n",
            "167\n",
            "175\n",
            "159\n"
          ]
        }
      ],
      "source": [
        "# calculate the length of the ragas_usecase_data page_content column for each document\n",
        "\n",
        "for doc in ragas_usecase_data:\n",
        "    print(len(doc.page_content))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Doc 0: 36 tokens\n",
            "Doc 1: 34 tokens\n",
            "Doc 2: 34 tokens\n",
            "Doc 3: 36 tokens\n",
            "Doc 4: 36 tokens\n",
            "Doc 5: 34 tokens\n",
            "Doc 6: 37 tokens\n",
            "Doc 7: 35 tokens\n",
            "Doc 8: 34 tokens\n",
            "Doc 9: 41 tokens\n",
            "Doc 10: 40 tokens\n",
            "Doc 11: 35 tokens\n",
            "Doc 12: 37 tokens\n",
            "Doc 13: 32 tokens\n",
            "Doc 14: 40 tokens\n",
            "Doc 15: 39 tokens\n",
            "Doc 16: 31 tokens\n",
            "Doc 17: 37 tokens\n",
            "Doc 18: 33 tokens\n",
            "Doc 19: 35 tokens\n",
            "Doc 20: 37 tokens\n",
            "Doc 21: 36 tokens\n",
            "Doc 22: 34 tokens\n",
            "Doc 23: 30 tokens\n",
            "Doc 24: 36 tokens\n",
            "Doc 25: 33 tokens\n",
            "Doc 26: 35 tokens\n",
            "Doc 27: 32 tokens\n",
            "Doc 28: 33 tokens\n",
            "Doc 29: 37 tokens\n",
            "Doc 30: 38 tokens\n",
            "Doc 31: 32 tokens\n",
            "Doc 32: 37 tokens\n",
            "Doc 33: 37 tokens\n",
            "Doc 34: 34 tokens\n",
            "Doc 35: 31 tokens\n",
            "Doc 36: 38 tokens\n",
            "Doc 37: 40 tokens\n",
            "Doc 38: 35 tokens\n",
            "Doc 39: 37 tokens\n",
            "Doc 40: 37 tokens\n",
            "Doc 41: 35 tokens\n",
            "Doc 42: 35 tokens\n",
            "Doc 43: 36 tokens\n",
            "Doc 44: 39 tokens\n",
            "Doc 45: 37 tokens\n",
            "Doc 46: 33 tokens\n",
            "Doc 47: 38 tokens\n",
            "Doc 48: 36 tokens\n",
            "Doc 49: 36 tokens\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "token_splitter = TokenTextSplitter()\n",
        "\n",
        "for i, doc in enumerate(ragas_usecase_data):\n",
        "    tokens = token_splitter._tokenizer.encode(doc.page_content)\n",
        "    print(f\"Doc {i}: {len(tokens)} tokens\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Documents appears to be too short (ie 100 tokens or less). Please provide longer documents.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtestset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestsetGenerator\n\u001b[32m      5\u001b[39m generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m dataset2 = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mragas_usecase_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/donbr-aie8-staging/aie8-s09-adv-retrieval/.venv/lib/python3.13/site-packages/ragas/testset/synthesizers/generate.py:170\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions, return_executor)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    166\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"An embedding client was not provided. Provide an embedding through the transforms_embedding_model parameter. Alternatively you can provide your own transforms through the `transforms` parameter.\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transforms:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     transforms = \u001b[43mdefault_transforms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransforms_llm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransforms_embedding_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# convert the documents to Ragas nodes\u001b[39;00m\n\u001b[32m    177\u001b[39m nodes = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/donbr-aie8-staging/aie8-s09-adv-retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/default.py:160\u001b[39m, in \u001b[36mdefault_transforms\u001b[39m\u001b[34m(documents, llm, embedding_model)\u001b[39m\n\u001b[32m    153\u001b[39m     transforms = [\n\u001b[32m    154\u001b[39m         summary_extractor,\n\u001b[32m    155\u001b[39m         node_filter,\n\u001b[32m    156\u001b[39m         Parallel(summary_emb_extractor, theme_extractor, ner_extractor),\n\u001b[32m    157\u001b[39m         Parallel(cosine_sim_builder, ner_overlap_sim),\n\u001b[32m    158\u001b[39m     ]\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDocuments appears to be too short (ie 100 tokens or less). Please provide longer documents.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m     )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m transforms\n",
            "\u001b[31mValueError\u001b[39m: Documents appears to be too short (ie 100 tokens or less). Please provide longer documents."
          ]
        }
      ],
      "source": [
        "# ALTERNATE\n",
        "\n",
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset2 = generator.generate_with_langchain_docs(ragas_usecase_data, testset_size=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "13-advanced-retrieval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
